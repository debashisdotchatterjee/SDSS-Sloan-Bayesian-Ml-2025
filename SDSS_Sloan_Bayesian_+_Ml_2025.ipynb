{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ6YCRv54JLO/3fxd+EzO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debashisdotchatterjee/SDSS-Sloan-Bayesian-Ml-2025/blob/main/SDSS_Sloan_Bayesian_%2B_Ml_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M-B9vHkWCcU",
        "outputId": "28035f6d-8bcd-4cd9-9db4-2bac9a20c574"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting jaxtyping (from gpytorch)\n",
            "  Downloading jaxtyping-0.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from gpytorch) (1.14.1)\n",
            "Collecting linear-operator>=0.6 (from gpytorch)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from linear-operator>=0.6->gpytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.6.0->gpytorch) (2.0.2)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch)\n",
            "  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->linear-operator>=0.6->gpytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (1.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->linear-operator>=0.6->gpytorch) (3.0.2)\n",
            "Downloading gpytorch-1.14-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, linear-operator, gpytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gpytorch-1.14 jaxtyping-0.3.1 linear-operator-0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 wadler-lindig-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URYe6GWjVtnf",
        "outputId": "cd506701-e212-47f5-b817-a5ba859e4bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   5/25  total=26.332  cls=0.349  gp=1.357\n",
            "epoch  10/25  total=18.016  cls=0.201  gp=0.871\n",
            "epoch  15/25  total=15.378  cls=0.176  gp=0.885\n",
            "epoch  20/25  total=14.984  cls=0.212  gp=0.923\n",
            "epoch  25/25  total=14.698  cls=0.132  gp=0.773\n",
            "✓ training finished in 19.6s\n",
            "\n",
            "==> files saved to sdss_bayes_output\n",
            "   classification_report.csv\n",
            "   colour_colour.png\n",
            "   confusion_matrix.png\n",
            "   loss_curve.png\n",
            "   redshift_hist.png\n",
            "   zscatter.png\n",
            "\n",
            "--- SDSS head (10) ---\n",
            "       objid         ra      dec        u        g        r        i        z  run  rerun  camcol  field    specobjid  class  redshift  plate   mjd  fiberid      g_r      r_i      i_z  y\n",
            "1.237650e+18 183.531326 0.089693 19.47406 17.04240 15.94699 15.50342 15.22531  752    301       4    267 3.722360e+18   STAR -0.000009   3306 54922      491  1.09541  0.44357  0.27811  0\n",
            "1.237650e+18 183.598370 0.135285 18.66280 17.21449 16.67637 16.48922 16.39150  752    301       4    267 3.638140e+17   STAR -0.000055    323 51615      541  0.53812  0.18715  0.09772  0\n",
            "1.237650e+18 183.680207 0.126185 19.38298 18.19169 17.47428 17.08732 16.80125  752    301       4    268 3.232740e+17 GALAXY  0.123111    287 52023      513  0.71741  0.38696  0.28607  1\n",
            "1.237650e+18 183.870529 0.049911 17.76536 16.60272 16.16116 15.98233 15.90438  752    301       4    269 3.722370e+18   STAR -0.000111   3306 54922      510  0.44156  0.17883  0.07795  0\n",
            "1.237650e+18 183.883288 0.102557 17.55025 16.26342 16.43869 16.55492 16.61326  752    301       4    269 3.722370e+18   STAR  0.000590   3306 54922      512 -0.17527 -0.11623 -0.05834  0\n",
            "1.237650e+18 183.847174 0.173694 19.43133 18.46779 18.16451 18.01475 18.04155  752    301       4    269 3.649550e+17   STAR  0.000315    324 51666      594  0.30328  0.14976 -0.02680  0\n",
            "1.237650e+18 183.864379 0.019201 19.38322 17.88995 17.10537 16.66393 16.36955  752    301       4    269 3.232870e+17 GALAXY  0.100242    287 52023      559  0.78458  0.44144  0.29438  1\n",
            "1.237650e+18 183.900081 0.187473 18.97993 17.84496 17.38022 17.20673 17.07071  752    301       4    269 3.722370e+18   STAR  0.000315   3306 54922      515  0.46474  0.17349  0.13602  0\n",
            "1.237650e+18 183.924588 0.097246 17.90616 16.97172 16.67541 16.53776 16.47596  752    301       4    270 3.638290e+17   STAR  0.000089    323 51615      595  0.29631  0.13765  0.06180  0\n",
            "1.237650e+18 183.973498 0.081626 18.67249 17.71375 17.49362 17.28284 17.22644  752    301       4    270 3.243690e+17 GALAXY  0.040508    288 52000      400  0.22013  0.21078  0.05640  1\n",
            "\n",
            "--- Classification report ---\n",
            "              precision  recall  f1-score   support\n",
            "STAR              0.961   0.972     0.966   830.000\n",
            "GALAXY            0.971   0.964     0.967  1000.000\n",
            "QSO               0.928   0.912     0.920   170.000\n",
            "accuracy          0.963   0.963     0.963     0.963\n",
            "macro avg         0.953   0.949     0.951  2000.000\n",
            "weighted avg      0.963   0.963     0.963  2000.000\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "#  Sloan Digital Sky Survey  –  Bayesian Deep‑Kernel Pipeline\n",
        "#  (author: ChatGPT, 18‑Apr‑2025)\n",
        "# ================================================================\n",
        "import os, time, random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics      import confusion_matrix, classification_report\n",
        "\n",
        "import torch, gpytorch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# CONFIGURATION – raise values for a full production run\n",
        "LATENT_DIM   = 16      # size of embedding\n",
        "NUM_INDUCING = 200     # sparse GP M (≥300 for highest fidelity)\n",
        "N_EPOCHS     = 25      # 150–200 for production\n",
        "BATCH_SIZE   = 512\n",
        "LR           = 3e-3\n",
        "SUBSAMPLE    = None    # e.g. 4000 for a <3‑min sanity run\n",
        "SEED         = 0\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "torch.manual_seed(SEED);  np.random.seed(SEED);  random.seed(SEED)\n",
        "\n",
        "CSV_PATH = Path('Skyserver_SQL2_27_2018 6_51_39 PM.csv')\n",
        "OUT_DIR  = Path('sdss_bayes_output');  OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ================================================================\n",
        "# 1.  DATA  &  BASIC FEATURES\n",
        "# ================================================================\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# colours\n",
        "df['g_r'] = df['g'] - df['r']\n",
        "df['r_i'] = df['r'] - df['i']\n",
        "df['i_z'] = df['i'] - df['z']\n",
        "\n",
        "# keep the three canonical label types\n",
        "class_map = {'STAR': 0, 'GALAXY': 1, 'QSO': 2}\n",
        "df = df[df['class'].isin(class_map)].copy()\n",
        "df['y']  = df['class'].map(class_map)\n",
        "\n",
        "if SUBSAMPLE:\n",
        "    df = df.sample(SUBSAMPLE, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "feat_cols   = ['u','g','r','i','z','g_r','r_i','i_z']\n",
        "scaler      = StandardScaler().fit(df[feat_cols])\n",
        "X_std       = scaler.transform(df[feat_cols])\n",
        "y           = df['y'].values.astype(np.int64)\n",
        "z_spec_full = df['redshift'].fillna(0.).values.astype(np.float32)\n",
        "\n",
        "# stratified split\n",
        "X_tr, X_te, y_tr, y_te, z_tr, z_te = train_test_split(\n",
        "    X_std, y, z_spec_full, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# torch datasets\n",
        "train_dl = DataLoader(\n",
        "    TensorDataset(torch.tensor(X_tr, dtype=torch.float32),\n",
        "                  torch.tensor(y_tr, dtype=torch.long),\n",
        "                  torch.tensor(z_tr, dtype=torch.float32)),\n",
        "    batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# ================================================================\n",
        "# 2.  MODEL PARTS\n",
        "# ================================================================\n",
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, d=LATENT_DIM):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(8, 64), nn.SiLU(),\n",
        "            nn.Linear(64, 32), nn.SiLU(),\n",
        "            nn.Linear(32, d))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class SparseGP(gpytorch.models.ApproximateGP):\n",
        "    \"\"\"Single‑task sparse variational GP for photometric z.\"\"\"\n",
        "    def __init__(self, d=LATENT_DIM, m=NUM_INDUCING):\n",
        "        inducing = torch.randn(m, d)\n",
        "        q_dist   = gpytorch.variational.CholeskyVariationalDistribution(m)\n",
        "        var_strat= gpytorch.variational.VariationalStrategy(\n",
        "            self, inducing, q_dist, learn_inducing_locations=True)\n",
        "        super().__init__(var_strat)\n",
        "        self.mean_module  = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
        "            gpytorch.kernels.RBFKernel())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return gpytorch.distributions.MultivariateNormal(\n",
        "            self.mean_module(x), self.covar_module(x))\n",
        "\n",
        "class SDSSBayes(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = EmbedNet()\n",
        "        self.gate  = nn.Linear(LATENT_DIM, 3)     # soft‑max head\n",
        "        self.gp    = SparseGP()                   # single‑task z‑GP\n",
        "    def forward(self, x):\n",
        "        h = self.embed(x)\n",
        "        return self.gate(h), self.gp(h), h\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model  = SDSSBayes().to(device)\n",
        "lik_gp = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
        "\n",
        "mll_gp = gpytorch.mlls.VariationalELBO(lik_gp, model.gp,\n",
        "                                       num_data=(y_tr!=0).sum()).to(device)\n",
        "optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# ================================================================\n",
        "# 3.  TRAIN\n",
        "# ================================================================\n",
        "model.train();  lik_gp.train()\n",
        "loss_hist = []\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(1, N_EPOCHS+1):\n",
        "    tot = 0.0\n",
        "    for xb, yb, zb in train_dl:\n",
        "        xb, yb, zb = xb.to(device), yb.to(device), zb.to(device)\n",
        "\n",
        "        logits, gp_all, _ = model(xb)\n",
        "        loss_cls = nn.functional.cross_entropy(logits, yb)\n",
        "\n",
        "        mask = (yb != 0)             # extragalactic subset\n",
        "        if mask.sum():\n",
        "            gp = model.gp(model.embed(xb[mask]))\n",
        "            targ = zb[mask]\n",
        "            loss_gp = -mll_gp(gp, targ)\n",
        "        else:\n",
        "            loss_gp = torch.tensor(0., device=device)\n",
        "\n",
        "        loss = loss_cls + loss_gp\n",
        "        optimiser.zero_grad();  loss.backward();  optimiser.step()\n",
        "        tot += loss.item()\n",
        "\n",
        "    loss_hist.append(tot)\n",
        "    if epoch % 5 == 0 or epoch == N_EPOCHS:\n",
        "        print(f'epoch {epoch:3d}/{N_EPOCHS}  total={tot:.3f}  cls={loss_cls.item():.3f}  gp={loss_gp.item():.3f}')\n",
        "\n",
        "print(f'✓ training finished in {time.time()-t0:.1f}s')\n",
        "\n",
        "# ================================================================\n",
        "# 4.  EVALUATION & PLOTS\n",
        "# ================================================================\n",
        "model.eval();  lik_gp.eval()\n",
        "\n",
        "# ---------- classification ------------\n",
        "X_te_t = torch.tensor(X_te, dtype=torch.float32, device=device)\n",
        "with torch.no_grad():\n",
        "    logits_te = model.gate(model.embed(X_te_t))\n",
        "    probs_te  = torch.softmax(logits_te, dim=1).cpu().numpy()\n",
        "y_pred = probs_te.argmax(1)\n",
        "\n",
        "cm   = confusion_matrix(y_te, y_pred, labels=[0,1,2])\n",
        "rep  = classification_report(y_te, y_pred,\n",
        "        target_names=['STAR','GALAXY','QSO'],\n",
        "        output_dict=True, zero_division=0)\n",
        "rep_df = pd.DataFrame(rep).T.round(3)\n",
        "rep_df.to_csv(OUT_DIR/'classification_report.csv')\n",
        "\n",
        "# ---------- figures -------------------\n",
        "# 1. colour–colour\n",
        "fig,ax = plt.subplots()\n",
        "ax.scatter(df['g_r'], df['r_i'], s=6, alpha=.5)\n",
        "ax.set_xlabel('g - r'); ax.set_ylabel('r - i')\n",
        "ax.set_title('Colour–Colour Diagram')\n",
        "fig.tight_layout(); fig.savefig(OUT_DIR/'colour_colour.png', dpi=300); plt.close(fig)\n",
        "\n",
        "# 2. red‑shift density\n",
        "fig,ax = plt.subplots()\n",
        "for cls in ['GALAXY','QSO']:\n",
        "    sub = df[df['class']==cls]['redshift']\n",
        "    ax.hist(sub,bins=40,density=True,histtype='step',label=cls)\n",
        "ax.set_xlabel('redshift'); ax.set_ylabel('density'); ax.legend()\n",
        "fig.tight_layout(); fig.savefig(OUT_DIR/'redshift_hist.png', dpi=300); plt.close(fig)\n",
        "\n",
        "# 3. training loss\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(loss_hist); ax.set_xlabel('epoch'); ax.set_ylabel('loss')\n",
        "ax.set_title('Training Loss')\n",
        "fig.tight_layout(); fig.savefig(OUT_DIR/'loss_curve.png', dpi=300); plt.close(fig)\n",
        "\n",
        "# 4. confusion matrix\n",
        "fig,ax=plt.subplots()\n",
        "im=ax.imshow(cm, cmap='Blues'); ax.set_xticks(range(3)); ax.set_yticks(range(3))\n",
        "ax.set_xticklabels(['STAR','GAL','QSO']); ax.set_yticklabels(['STAR','GAL','QSO'])\n",
        "ax.set_xlabel('predicted'); ax.set_ylabel('true')\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax.text(j,i,cm[i,j],ha='center',va='center',\n",
        "                color='white' if cm[i,j]>cm.max()*0.6 else 'black')\n",
        "fig.tight_layout(); fig.savefig(OUT_DIR/'confusion_matrix.png', dpi=300); plt.close(fig)\n",
        "\n",
        "# 5. z‑scatter (only extragalactic in test set)\n",
        "mask_ex = y_te!=0\n",
        "with torch.no_grad():\n",
        "    mu = model.gp(model.embed(torch.tensor(X_te[mask_ex], dtype=torch.float32,\n",
        "                                           device=device))).mean.cpu().numpy()\n",
        "fig,ax = plt.subplots()\n",
        "ax.scatter(z_te[mask_ex], mu, s=10, alpha=.6)\n",
        "ax.plot([0,z_te.max()],[0,z_te.max()], ls='--', lw=1)\n",
        "ax.set_xlabel('z (spec)'); ax.set_ylabel('ẑ (phot)')\n",
        "ax.set_title('Photometric vs. Spectroscopic z')\n",
        "fig.tight_layout(); fig.savefig(OUT_DIR/'zscatter.png', dpi=300); plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# 5.  CONSOLE PREVIEW\n",
        "# ================================================================\n",
        "print(\"\\n==> files saved to\", OUT_DIR)\n",
        "for f in sorted(os.listdir(OUT_DIR)): print(\"  \", f)\n",
        "\n",
        "print(\"\\n--- SDSS head (10) ---\")\n",
        "print(df.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Classification report ---\")\n",
        "print(rep_df.to_string())\n"
      ]
    }
  ]
}